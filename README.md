# House-Price-Prediction

# Project Overview

The Ames Housing dataset, compiled by Dean De Cock, is a comprehensive and modernized alternative to the Boston Housing dataset. It contains detailed information about residential properties, including structural features, quality ratings, and location-based attributes.

The objective of this project is to predict property sale prices using advanced regression techniques. Due to the datasetâ€™s high dimensionality and complex feature relationships, extensive feature engineering and preprocessing are required to achieve high predictive accuracy.

# Problem Statement
To build a machine learning model that accurately predicts the sale price of houses based on multiple numerical and categorical features.

# Dataset Information
- Source: Ames Housing Dataset (Dean De Cock)
- Number of Features: 70+ explanatory variables
- Target Variable: SalePrice
- Data Type: Numerical & Categorical
- Challenges:
   - Missing values
   - High cardinality categorical variables
   - Non-linear relationships
   - Skewed target distribution
 
# Technologies & Libraries Used

- Programming Language: Python
- Libraries:
  - NumPy
  - Pandas
  - Matplotlib
  - Seaborn
  - Scikit-learn
  - XGBoost

# Project Workflow
1ï¸âƒ£ Data Loading & Exploration
- Loaded training and test datasets
- Performed exploratory data analysis (EDA)
- Identified missing values and outliers

2ï¸âƒ£ Data Preprocessing
- Handled missing numerical features using median imputation
- Filled missing categorical values with meaningful placeholders
- Removed irrelevant or redundant features

3ï¸âƒ£ Feature Engineering
- Created new meaningful features such as:
- Total square footage
- Applied log transformation to the target variable to reduce skewness
- Encoded categorical variables using label encoding

4ï¸âƒ£ Model Building
- Implemented and compared multiple regression models:
- Linear Regression (Baseline)
- Random Forest Regressor
- XGBoost Regressor (Final Model)

5ï¸âƒ£ Model Evaluation
- Used Root Mean Squared Error (RMSE) as the evaluation metric
- Compared model performance on validation data
- Selected the best-performing model based on RMSE

# Project Structure
  
   House-Price-Prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model.pkl
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## Models Trained

| Model | RMSE |
|------|------|
| Linear Regression | 0.18 |
| Random Forest Regressor | 0.14 |
| XGBoost Regressor | 0.12 |

## ğŸ† Best Model
XGBoost Regressor performed the best with the lowest RMSE.


# Results

Model: XGBoost Regressor  
Evaluation Metric: RMSE  

The XGBoost model significantly improved prediction accuracy
compared to baseline models due to boosting and log transformation.

